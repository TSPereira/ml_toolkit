import scipy as sp
import scipy.sparse
import numpy as np
import pandas as pd
import pickle
from sklearn.cluster import KMeans, DBSCAN, MiniBatchKMeans
from sklearn.neighbors import KNeighborsClassifier
from kmodes.kmodes import KModes
from kmodes.kprototypes import KPrototypes
from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score
from sklearn.preprocessing import MinMaxScaler, MultiLabelBinarizer
import matplotlib.pyplot as plt
import seaborn as sns
from ..clustering.clustering_estimators import WeightedEstimator
from ..clustering.plot_functions import take_outliers_graph, plot_metrics
from ..clustering.silhouette_custom import silhouette_score_block
from textwrap import wrap
from ..feature_selection import GiniFeatureSelector, CrossProjection
from ..feature_encoding import feature_encoders
from ..utils import printv
import warnings


class Predictions(object):
    """Container class to hold predictions relative to a cluster model"""

    def __init__(self, index):
        # input
        self.index = index

        # outputs
        self.data_not_predicted = {'missing_data': [],
                                   'not_encoded': []}
        self.probabilities = None
        self.labels = None

    def get_labels_with_index(self):
        """Associate predicted labels with the correct index
        :return: Pandas Series with labels as values and index as index
        """

        try:
            _not_predicted = sum(self.data_not_predicted.values(), [])
            _index = self.index[~self.index.isin(_not_predicted)]
            return pd.Series(self.labels.astype(str), index=_index, name='labels')
        # todo find type of except
        except:
            return pd.Series(name='labels')

    def get_labels_and_probability(self):
        """Additionally to returning labels, also returns the probability of belonging to that label
        :return: Pandas DataFrame with labels and probability as values and index as index
        """

        try:
            _df = self.get_labels_with_index().to_frame('cluster_id')
            _proba = self.probabilities[np.arange(self.probabilities.shape[0]), self.labels]
            _df['cluster_accuracy'] = _proba
            return _df
        except:
            return pd.DataFrame(columns=['cluster_id', 'cluster_accuracy'])


class BaseCluster(object):
    """
    Base Cluster class
    This class implements a pipeline for clustering using some known methods and metrics.

    Parameters
    ----------

    name: string, mandatory
        name of the class instance to identify the clustering in later stages

    method: {'kmeans', 'minibatchkmeans' or 'kmodes'}, default: 'minibatchkmeans'
        method to use for clustering.
        depending on the chosen method, a different set of default method parameters to be evaluated
        is defined

    verbose: bool, optional, default: False
        parameter to control verbosity

    random_state: int, optional, default: 0
        parameter to ensure reproducibility


    Attributes
    ----------
    (defined directly to the corresponding attributes. All Optional)

    method_params: default: dependant on method chosen
        parameter to control hyper parameters to be tested by the algorithm.
        if introduced by the user the parameters passed will be checked against the method chosen
        if not chosen, the parameter defaults to the method standard parameters (implemented by the class)

        kmeans, minibatchkmeans, kmodes, kprototypes, kmedoids:
            {min_n_clusters: 1, max_n_clusters: 30}

        DBSCAN:
            {min_eps: 0.05, max_eps: 5, nr_steps_eps: 10,
            min_samples_min: 10, min_samples_max: 100, nr_steps_min_samples: 10}

    metrics: {'all', None, 'Silhouette Coefficient, Calinski-Harabasz, Davies-Bouldin}
        Defines the metrics to evaluate the clustering with. Defaults to 'all' of the implemented metrics
        The chosen metrics will be evaluated and stored in parameter 'metrics_results'. If a save_plots_path is passed
        plots generated by the metrics will be produced and saved.

    # todo lock some attributes from edition (define __setattr__ and test with hasattr)
    n_clusters: default: None
        number of clusters calculated. This is just an informative attribute, as it will be overriden by
        the method calculation. To explicitly pass the number of clusters use the 'best_params' attribute

    # todo check best_params against the method chosen
    best_params: dict, default: {}
        with this attribute one can pass parameters for the method to evaluate. the existence of some parameter
        within this attribute, will bypass the gridsearch created by 'method_params' and will evaluate directly
        the model with the chosen 'best_params'.
        *Passing a wrong key will result in using a std parameter for the algorithm.
        examples: {'n_clusters': 10}
                  {'eps': 3, 'min_samples': 20}

        'best_params' can be managed using methods: set_best_param, del_best_param and clear_best_param

    auto_feature_selection: bool, default: False
        parameter to control whether the algorithm should look for subsets of features automatically
        number of subsets evaluated is controled by 'n_feature_models'
        As a standard this class uses Gini Impurity calculation with Cross Projection Normalization and a
        scatter separability score to evaluate subsets of features vs their resulting labels.
        Feature selector and evaluator can be overriden in superseeding classes by overriding methods
        'auto_feature_selector' and 'auto_hyperparameter_evaluator'

    n_feature_models: int, default: 10
        number of subsets of features to run automatic feature selection on

    gamma: dict, default: {}
        with this attribute the user can control the weight the algorithm will give to a specific (or set of)
        feature. This way the user can introduce bias to the features he considers more important for his analysis
        example: {'brand': 1.5}

    calculate_gamma: bool, default: True
        If no specific gamma is given by the user to a feature, then the algorithm will calculate a value for
        gamma for each feature. This value will be such that categorical features have the same impact as continuous
        features and it is calculated using the avg std deviations of the continuous features and the std deviation
        of each categorical feature


    Attributes
    ----------------
    (used to store data or results)

    cleaned_data: default: None
        data after cleaning. passed directly on the 'fit' method

    used_features: default: None
        User must pass a list of features (existing in the passed data) to be used by the algorithm. If
        None the algorithm will raise a ValueError as this attribute is needed for indexing.
        If 'auto_feature_selection' = True, the algorithm will only choose from the list passed.

    encoded_data:
        data after encoded

    metrics_results:
        arrays resulting of the metrics evaluation. will change depending on the method chosen.

        {'kmeans', 'minibatchkmeans' or 'kmodes'}: metric_results will be arrays of format
            [n_clusters, [sum of squared errors, metrics**]]

        {'DBSCAN'}: metric_results will be arrays of format
            [eps, min_sample, [n_clusters_estimated, % mislabeled records, metrics**]

    save_plots_path:
        path to save resulting plots of metrics

    final_model_data:
        data encoded and filtered to the features to be used in the final model evaluation

    model:
        class with the model of the method used


    Conditional Attributes
    ----------------
    If method 'predict' is used, the class will be extended with an attribute containing methods and parameters specific
    for this instance

    predictions:
        Instance of Class Predictions
    """

    _clustering_algorithms = ['kmeans', 'minibatchkmeans', 'kmodes']
    # todo reintroduce DBSCAN kprototypes

    def __init__(self, name, method='minibatchkmeans', verbose=False, random_state=0):
        self.name = name
        self.method = method
        self.method_params = self._get_std_params()
        self.metrics = check_metrics('all')
        self.n_clusters = None
        self.best_params = dict()
        self.auto_feature_selection = False
        self.n_feature_models = 10
        self.gamma = dict()
        self.calculate_gamma = True
        self.verbose = verbose
        self.random_state = random_state

        self.cleaned_data = None
        self.used_features = None
        # self.removed_features = None
        self.encoded_data = None
        self.metrics_results = dict()
        self.save_plots_path = None
        self.final_model_data = None
        self.model = None

    def _get_std_params(self):
        """Defines standard parameters depending on the method chosen for clustering

        :return dict: dictionary with parameter names as keys and their respective values
        """

        self._check_method()
        if self.method in ['kmeans', 'minibatchkmeans', 'kmodes', 'kprototypes']:
            _std_params = {'min_n_clusters': 1,
                           'max_n_clusters': 30}
        elif self.method in ['DBSCAN']:
            _std_params = {'min_eps': 0.05,
                           'max_eps': 5,
                           'nr_steps_eps': 10,
                           'min_samples_min': 10,
                           'min_samples_max': 100,
                           'nr_steps_min_samples': 10}

        else:
            raise IOError('Method introduced has no standard hyperparameters to explore. '
                          'Input parameters to explore into \'self.method_params\'')

        return _std_params

    def _check_method(self):
        """Verifies if the method introduced by the user is implemented

        :return: None
        """

        if self.method not in self._clustering_algorithms:
            raise AssertionError('Method introduced is not supported. Choose one from {}'.format(
                self._clustering_algorithms))

    def _check_params(self):
        """Decorator method that calls the function 'check_params' to verify if the specific parameters passed by the
         user are acceptable for the method chosen

        :return: None
        """
        check_params(self.method_params, self.method)

    def _check_metrics(self):
        """Decorator method that calls the function 'check_metrics' to evaluate if the metrics chosen by the user are
        supported by the algorithm"""
        check_metrics(self.metrics)

    def _auto_feature_selector(self):
        """This method can be overriden by dependant class to use a custom automatic feature selector

        As a standard this class uses a Gini Impurity Feature Selector, based on the values of Gini Impurity
        between the features and removing iteratively by the higher values observed.

        Any superseeding class must implement a method 'subset()' returning the next subset of features and an
        attribute 'current_subset_id' which identifies the subset further on.

        In the case of the GiniFeatureSelector here implemented the 'current_subset_id' identifies the gini value
        use as threshold to obtain the current subset being yielded

        :return: None
        """
        self.feature_selector = GiniFeatureSelector(pd.DataFrame(self.encoded_data.toarray()), self.n_feature_models,
                                                    verbose=self.verbose)

    def _auto_hyperparameter_evaluator(self):
        """This method can be overriden by dependant class to use a custom automatic feature selector

        As a standard this class uses a method named Cross Projection Normalization to evaluate the combinations
        of feature subsets and resulting labels

        Any superseeding class must implement a method 'evaluate()' returning a tuple of
        (optimal_subset, optimal_hyperparameter) and a method 'add_data()' to append a dictionary of format
        {subset_id: (clustering_data, labels_for_all_clusters_ran)}

        :return: None
        """

        # must have a add_data method and an evaluate method. Must return subset of best data and best params
        self.hyperparameter_evaluator = CrossProjection(verbose=self.verbose)

    def _eval_hyperparameters(self):
        """Method that depending on the clustering method chosen will evaluate and chose which are the best parameters
        for the model (from the ones tested)

        :return: None
        """

        if self.auto_feature_selection:
            self.final_model_data, _params = self.hyperparameter_evaluator.evaluate()

            if self.method in ['kmeans', 'minibatchkmeans', 'kmodes', 'kprototypes']:
                self.n_clusters = _params
                self.best_params['n_clusters'] = self.n_clusters

            elif self.method == 'DBSCAN':
                _params = _params.split(' | ')
                self.best_params['eps'], self.best_params['min_samples'] = [float(x) for x in _params]

        else:
            if self.method in ['kmeans', 'minibatchkmeans', 'kmodes', 'kprototypes']:
                self.n_clusters = eval_cluster_fitness(self.metrics_results[:, 0], dim=self.encoded_data.shape)
                self.best_params['n_clusters'] = self.n_clusters
        # todo find best way to evaluate DBSCAN

    def _run_hyperparameters(self, data):
        """Method that evaluates the model for all the hyperparameters chosen and finally calls the method that will
        choose the best hyperparameters seen ('_eval_hyperparameters')

        :param np.ndarray data: encoded data array to pass to the clustering model
        :return: None
        """

        scores, key, hyper_results = run_hyperparameters(sp.sparse.csr_matrix(data), self.method, self.method_params,
                                                         self.metrics, verbose=self.verbose)

        if self.auto_feature_selection:
            _subset_id = self.feature_selector.current_subset_id
            self.metrics_results[_subset_id] = scores
            self._plot_metrics(scores, key, name=_subset_id)
            self.hyperparameter_evaluator.add_data({_subset_id: hyper_results})

            try:
                _data = self.feature_selector.subset()
                self._run_hyperparameters(_data)
            except StopIteration:
                self._eval_hyperparameters()

        else:
            self.metrics_results = scores
            self._plot_metrics(scores, key)
            self._eval_hyperparameters()
            self.final_model_data = data

    def _get_best_model(self):
        """Method that evaluates the model with the best hyperparameters found previously (or passed by the user)

        :return: None
        """

        _, _, _, self.model = clustering(sp.sparse.csr_matrix(self.final_model_data), method=self.method,
                                         verbose=self.verbose, **self.best_params)

    def _predictor(self, _data, return_proba=False):
        """This method can be overriden by dependant class to use a custom cluster predictor

        As a standard this class uses a KNN Classifier to predict the new data clusters.
        Any superseeding class should save the results of the 'predict()' method to 'self.prediction.labels' (an
        attribute created by the extension of the current class with the class 'Predictions') and optionally save the
        probabilities to belong to each cluster to 'self.prediction.probabilities'

        :param np.ndarray _data: data to predict clusters for
        :param bool return_proba: default: False. Whether to return the probabilities of each register to belong to
        each cluster
        :return: None
        """

        # Get # of neighbours to use
        nr_neigh = len(np.unique(self.model.labels_))
        if nr_neigh % 2 == 0:
            nr_neigh += 1
        else:
            nr_neigh += 2

        # Create and fit classifier and perform predictions for the inputed data
        knn = KNeighborsClassifier(nr_neigh, weights='distance', n_jobs=-2)
        knn.fit(self.final_model_data, self.model.labels_)
        self.predictions.labels = knn.predict(_data)

        if return_proba:
            self.predictions.probabilities = knn.predict_proba(_data)

    def _plot_metrics(self, scores, key, name='original dataset'):
        """Decorator method to plot the metrics requested by the user

        :param np.ndarray scores: score values of each metric
        :param string key: axis values to plot the metrics on
        :param string name: default: 'original dataset'. Name to print on the plot
        :return: None
        """

        _name = self.name + ' ' + name
        plot_metrics(scores, key, metrics=self.metrics, method=self.method, save_path=self.save_plots_path, name=_name)

    def clear_best_param(self):
        """Utilitary method to clean the 'best_params' attribute and reinitialize it to an empty dictionary

        :return: None
        """
        self.best_params = dict()

    def del_best_param(self, param):
        """Utilitary method to delete one parameter from the dictionary of 'best_params'

        :param string param: parameter name to delete
        :return: None
        """
        self.best_params.__delattr__(param)

    def set_best_param(self, param, value):
        """Utilitary method to introduce a new parameter into the dictionary of 'best_params' to evaluate

        :param string param: parameter name to insert
        :param value: parameter value
        :return:
        """
        self.best_params[param] = value

    def get_data_with_labels(self):
        """Append labels to the cleaned dataset
        :return: pandas DataFrame
        """

        if self.model is None:
            raise ValueError('Model was not calculated or assigned yet.')

        if self.model.labels_ is None:
            raise ValueError('Labels were not calculated or assigned yet.')

        if self.cleaned_data is None:
            raise ValueError('\'cleaned_data\' attribute is empty. Assign it or input raw_data and run the '
                             '\'clean_data\' method')

        _labels = pd.DataFrame(self.model.labels_, index=self.get_used_data().index, columns=['labels']).astype(str)
        _data_with_labels = pd.merge(self.cleaned_data, _labels, how='left', left_index=True, right_index=True)
        return _data_with_labels

    def get_used_data(self, data=None):
        """Filter cleaned data with the used_features

        :param data: if 'data' is passed use that DataFrame. Else use the DataFrame stored in 'self.cleaned_data'
        :return: pandas DataFrame
        """

        try:
            if data is not None:
                _cols = [col for col in data.columns if col in self.used_features]
                _used_data = data[_cols]
            else:
                _used_data = self.cleaned_data[self.used_features]
        except:
            raise ValueError('Can not retrieve used data. Confirm that \'used_features\' and \'cleaned_data\' '
                             'attributes are defined correctly.')
        else:
            _used_data = _used_data.dropna().sort_index(axis=1)
            return _used_data

    def encode(self, data, **kwargs):
        """Function to encode data to a suitable format for the method to be use.
        In this base class this method is just a wrapper to how the call should be done. This method is meant to
        be overriden by project specific superseeding class method

        :param pandas.DataFrame data: cleaned data to encode
        :param kwargs: any parameter that method should take, namely 'train' to control behaviour during train or
        prediction
        :return: numpy array or pandas DataFrame

        Example of superseeding function on dependant class:

        def encode(self, data, train=False):
            # Train/prediction actions
            if train:
                self.encoded_data, self.encoders = feature_encoders.encode_training(data=data, method=self.method,
                                                                                    gamma=self.gamma,
                                                                                    calc_gamma=self.calculate_gamma,
                                                                                    verbose=self.verbose)
                return self.encoded_data
            else:
                if (self.encoders is not None) & (self.encoded_data is not None):
                    #Data not encoded in 2nd position of the resulting tuple
                    encoded_data, data_not_encoded = feature_encoders.encode_predict(
                        data=data, encoders=self.encoders, dim=self.encoded_data.shape[1], verbose=self.verbose)

                    if hasattr(self, 'predictions'):
                        self.predictions.data_not_encoded = data_not_encoded
                        return encoded_data
                    else:
                        print('Data not encoded in 2nd position of the resulting tuple')
                        return encoded_data, data_not_encoded

                else:
                    raise ValueError('\'encoders\' or \'encoded_data\' are not assigned. Fit original data or assign '
                                     'these attributes to be able to encode prediction data')

        """

        raise AssertionError('Override method \'encode\' within a dependant class. Output should be encoded_data')

    def fit(self, cleaned_data=None):
        """Method to fit the model to the cleaned data.

        :param pandas.DataFrame cleaned_data: Optional. default: None. If passed the DataFrame will be assigned to
        'self.cleaned_data' and it will be used from then on. If 'None', algorithm will check if self.cleaned_data is
        attributed and if so will continue
        :return: best model class
        """

        if self.verbose:
            warnings.warn('Base class \'fit\' method will only run with cleaned data and user must assign '
                          '\'used_features\' attribute previously. \'used_features\' can be then filtered automatically'
                          ' through usage of \'auto_feature_selection\' parameter.'
                          'To run fit directly on raw_data, extend the \'fit\' method on a dependant class to perform '
                          'the necessary data cleaning for the specific situation.')

        if cleaned_data is not None:
            self.cleaned_data = cleaned_data

        if self.cleaned_data is None:
            raise ValueError('There is no cleaned data to proceed. Assign \'cleaned_data\'')

        printv('Clustering {}...'.format(self.name), verbose=self.verbose)
        _data = self.get_used_data()
        self.encoded_data = self.encode(_data, train=True)

        if not self.best_params:
            if self.auto_feature_selection:
                self._auto_feature_selector()
                self._auto_hyperparameter_evaluator()
            self._run_hyperparameters(data=self.encoded_data)
        else:
            self.final_model_data = self.encoded_data

        self._get_best_model()

        return self.model

    def predict(self, data, return_proba=False):
        """Method to predict the cluster of new data using the training set and labels
        :param pandas.DataFrame data: data to predict
        :param bool return_proba: whether the algorithm should calculate and return the probability to belong to each
        cluster
        :return pandas.Series: Series with labels for each index
        """

        self.predictions = Predictions(data.index)
        _data = self.get_used_data(data)
        # assert which records were not predicted cause there is missing data on the used features
        self.predictions.data_not_predicted['missing_data'] += data.index[~data.index.isin(_data.index)].tolist()

        if not _data.empty:
            _encoded_data = self.encode(_data, train=False)

            if _encoded_data.shape[0] > 0:
                printv('Predicting {} {}'.format(_encoded_data.shape[0], self.name), verbose=self.verbose)
                self._predictor(_encoded_data, return_proba=return_proba)
                return self.predictions.get_labels_with_index()

        printv('No {} records valid to predict.'.format(self.name), verbose=self.verbose)
        return self.predictions.get_labels_with_index()

    def fit_predict(self, cleaned_data):
        """Fits the data as in the 'fit' method and return the labels for the training set

        :param pandas.DataFrame cleaned_data: data to fit the model on and return respective clusters
        :return numpy.array: array with labels for each record
        """
        self.fit(cleaned_data)
        return self.model.labels_

    def save(self, params=True):
        """Method to save the entire class or only the running parameters
        :param bool params: default: True. if params is True, method will not save any data. else it will save
        everything
        :return: None
        """

        dict_to_save = self.__dict__.copy()
        _name = self.name + '_full_class.txt'

        if params:
            data_keys = [key for key in dict_to_save if key.endswith('data')]
            other_keys = ['model', 'metrics_results']

            for key in data_keys+other_keys:
                dict_to_save[key] = None

            _name = self.name + '_params.txt'

        with open(self.save_plots_path + _name, 'wb') as h:
            h.write(pickle.dumps(dict_to_save))

        if params:
            print('Class parameters saved.')
        else:
            print('Full class (with data) saved.')

    def load(self, path):
        """Method to load attributes from previously saved file.
        :param string path: path to saved file
        :return: None
        """

        with open(path, 'rb') as h:
            self.__dict__ = pickle.loads(h.read())
        print('Data loaded successfully.')


class Cluster(BaseCluster):
    def __init__(self, name, method='minibatchkmeans', verbose=False, random_state=0):
        super().__init__(name, method=method, verbose=verbose, random_state=random_state)

        self.encoders = list()


    def encode(self, data, train=False):
        # Train/prediction actions
        if train:
            self.encoded_data, self.encoders = feature_encoders.encode_training(data=data, method=self.method,
                                                                                gamma=self.gamma,
                                                                                calc_gamma=self.calculate_gamma,
                                                                                verbose=self.verbose)
            return self.encoded_data
        else:
            if self.encoders is not None:
                # Data not encoded in 2nd position of the resulting tuple
                # Data not encoded is the assertion of records not predicted cause there are new categories in some feat
                encoded_data, data_not_encoded = feature_encoders.encode_predict(data=data, encoders=self.encoders,
                                                                                 verbose=self.verbose)

                if hasattr(self, 'predictions'):
                    self.predictions.data_not_predicted['not_encoded'] += data_not_encoded
                    return encoded_data
                else:
                    print('Data not encoded in 2nd position of the resulting tuple')
                    return encoded_data, data_not_encoded

            else:
                raise ValueError('\'encoders\' or \'encoded_data\' are not assigned. Fit original data or assign these '
                                 'attributes to be able to encode prediction data')


def clustering(x, method='kmeans', random_state=0, verbose=0, **kwargs):
    """
    Function to perform clustering of a dataset

    :param numpy.ndarray|scipy.sparse.csr_matrix x: Data to cluster
    :param string method: default: 'kmeans'. Method of clustering to use. Suports K-Means, MiniBatch K-Means and DBSCAN
    :param int random_state: default: 0. Variable to set the random state for reproducibility
    :param int verbose: default: 0. Controls if method prints info to console. Higher numbers produce more detailed info
    :param kwargs: Other named parameters to be used as hyper-parameters to test for the chosen method

    :return: numpy.ndarray labels: Array with the labels of each cluster for each example in x
    :return: numpy.ndarray x_clust: Cluster centroid coordinates (only available for K-Means or MiniBatch K-Means)
    :return: numpy.ndarray err: Sum of the distances of all examples in a cluster to its centroids. One error metric.
                                (only available for K-Means or MiniBatch K-Means)
    """

    # method and respective std parameters definition
    _methods = {'kmeans': dict(model=KMeans, std_kwargs=dict(n_init=30, max_iter=2000)),
                'minibatchkmeans': dict(model=MiniBatchKMeans,
                                        std_kwargs=dict(n_init=15, max_iter=1000,
                                                        batch_size=max(1, int(x.shape[0] / 100)))),
                'kmodes': dict(model=KModes, std_kwargs=dict(max_iter=300, n_init=10)),
                'kprototypes': dict(model=KPrototypes, std_kwargs=dict(max_iter=300, init='Cao', categorical=None)),
                'DBSCAN': dict(model=DBSCAN, std_kwargs=dict())
                }

    # Check if the method to use is implemented
    assert method in _methods.keys(), f'Method chosen is not supported. Choose method from: {_methods.keys()}'
    _method = _methods[method]

    # get correct arguments for chosen method (get std_kwargs if not passed in kwargs, add random_state and verbose (
    # reduced for model) and filter kwargs for the existing arguments in the model chosen)
    _model_verbose = 0 if verbose <= 1 else verbose - 1
    _std_kwargs = {key: value for key, value in _method['std_kwargs'].items() if key not in kwargs.keys()}
    kwargs = {**kwargs, **_std_kwargs, **dict(random_state=random_state, verbose=_model_verbose)}
    _kwargs = {key: value for key, value in kwargs.items() if hasattr(_method['model'](), key)}

    # Fit the chosen model
    labels = x_clust = err = model = None
    if method in ('kmeans', 'minibatchkmeans'):
        n_clusters_ = _kwargs['n_clusters'] if 'n_clusters' in _kwargs else 8
        printv(f'Clustering with {method} for {n_clusters_} clusters...', verbose=verbose)

        model = _method['model'](**_kwargs).fit(x)
        x_clust, labels, err = sp.sparse.csr_matrix(model.cluster_centers_), model.labels_, model.inertia_

    elif method == 'kmodes':
        n_clusters_ = _kwargs['n_clusters'] if 'n_clusters' in _kwargs else 8
        printv(f'Clustering with {method} for {n_clusters_} clusters...', verbose=verbose)

        x_ = x if isinstance(x, np.ndarray) else x.toarray()
        model = _method['model'](**_kwargs).fit(x_)
        x_clust, labels, err = sp.sparse.csr_matrix(model.cluster_centroids_), model.labels_, model.cost_

    elif method == 'kprototypes':
        n_clusters_ = _kwargs['n_clusters'] if 'n_clusters' in _kwargs else 8
        printv(f'Clustering with {method} for {n_clusters_} clusters...', verbose=verbose)

        x_ = x if isinstance(x, np.ndarray) else x.toarray()
        model = _method['model'](**_kwargs).fit(x_, None, kwargs['categorical'])
        x_clust, labels, err = model.cluster_centroids_, model.labels_, model.cost_

    elif method == 'DBSCAN':
        eps_ = _kwargs['eps'] if 'eps' in _kwargs else 0.5
        min_samples_ = _kwargs['min_samples'] if 'min_samples' in _kwargs else 5
        printv(f'Clustering with DBSCAN for {eps_} eps and {min_samples_} minimum samples...', verbose=verbose)

        # DBSCAN doesn't calculate cluster centers and thus doesn't have an error return either
        model = _method['model'](**_kwargs).fit(x)
        labels = model.labels_

        # Calculates the estimate of clusters
        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
        printv('The estimated number of clusters is: {}'.format(n_clusters_), level=2, verbose=verbose)

    return labels, x_clust, err, model


def score_clustering(x, labels, metrics='all'):
    """Function that calculates the scores for each metric requested by the user
    todo STILL NEEDS REVIEWING

    :param numpy.ndarray|scipy.sparse.csr_matrix x: Data used for clustering
    :param numpy.ndarray labels: Labels of each cluster obtained previously
    :param string|list metrics: default: 'all'. Requested metrics. Implemented for Silhouette Coefficient,
    Calinski-Harabasz and Davies-Bouldin. Option 'all' returns all that are implemented. New implementations need to
    have the metrics limits implemented as well

    :return: numpy.ndarray vec_coefs: Array of shape (n, 1) with the metrics values. n is the number of metrics
    requested
    :return: met_limits: Calculated_Matrixes with the limits for each metric in the same positions as the metrics values
    """

    # Checks input metrics
    check_metrics(metrics)

    # Initialize dictionaries with each metric implemented and their limits
    coefs_dict = {'Silhouette Coefficient': 0,
                  'Calinski-Harabasz':      1,
                  'Davies-Bouldin':         2,
                  'Scatter Separability':   3}

    metric_limits = {'Silhouette Coefficient': [-1, 1],
                     'Calinski-Harabasz':      [0, float('inf')],
                     'Davies-Bouldin':         [0, 1],
                     'Scatter Separability':   [0, float('inf')]}

    # If the number of clusters assigned is bigger than one, calculate the metrics
    if len(np.unique(labels)) > 1:
        x = x.toarray()

        s_coef = silhouette_score_block(x, labels, sample_size=min(50000, x.shape[0]))
        cal_har = calinski_harabasz_score(x, labels)
        dav_bould = davies_bouldin_score(x, labels)

    # If only one or zero clusters were found, then assign inf (so it won't show on the plots)
    else:
        s_coef = float('inf')
        cal_har = float('inf')
        dav_bould = float('inf')

    # Save the calculated metrics to a vector
    vec_coefs = np.array([s_coef, cal_har, dav_bould])
    # Get the slice numbers for the selected metrics
    met_limits = np.matrix([metric_limits[key] for key in metric_limits])

    # If only some specific metrics were requested, get those from the vector and their limits
    if metrics != 'all':
        try:
            metrics_label = [coefs_dict[key] for key in metrics]
        except KeyError:
            metrics_label = None
            pass

        if metrics_label:
            vec_coefs = vec_coefs[metrics_label]
            met_limits = met_limits[metrics_label]
        else:
            print('No valid metrics were chosen.')
            raise KeyError

    return vec_coefs, met_limits


def run_hyperparameters(x, method, params, metrics='all', categories=None, verbose=0):
    """Function to run several hyper-parameters and get the score of the clustering algorithm for each hyper-parameter
    combination

    :param numpy.ndarray|scipy.sparse.csr_matrix x: Data encoded, ready to go into a clustering algorithm
    :param string method: Method to use for clustering. One of ['kmeans', 'minibatchkmeans', 'kmodes', 'kprototypes',
    'DBSCAN']
    :param dict params: Hyper-parameters to use. eg for 'kmeans': {'min_n_clusters': 1, 'max_n_clusters': 10}
    :param string|list metrics: default: 'all'. List of metrics to evaluate. Default string 'all' will evaluate all
    implemented metrics
    :param list categories: default: None. List with index of columns that are categorical to be used in K-Prototypes
    method
    :param int verbose: default: 0. Controls if method prints info to console. Higher numbers produce more detailed info

    :return: numpy.ndarray scores: array containing the evaluation metrics requested for chosen method.
    'kmeans' always returns the sum of the distances (err) in first column
    'DBSCAN' returns the number of clusters estimated and the % of non-labeled records in the first two columns
    :return: numpy.array|tuple key: key to be used for plotting containing the hyper-parameters tried
    """

    methods = ['kmeans', 'minibatchkmeans', 'kmodes', 'kprototypes', 'DBSCAN']

    check_params(params, method)
    metrics = check_metrics(metrics)

    # Get the number of metrics to evaluate for array initialization purposes
    if metrics == 'all':
        sh = 3
    elif metrics is None:
        sh = 0
    else:
        sh = len(metrics)

    if method in ['kmeans', 'minibatchkmeans', 'kmodes', 'kprototypes']:
        # Get the hyper-parameter space to run from the hyper-parameters introduced
        nr_cluster_space = np.linspace(params['min_n_clusters'], params['max_n_clusters'],
                                       num=params['max_n_clusters'] - params['min_n_clusters'] + 1).astype(int)

        # Initialize the array for metrics and the key for their plot
        scores = np.zeros((nr_cluster_space.shape[0], 1 + sh))   # err + number of metrics asked
        key = nr_cluster_space

        hyper_results = {'ohe_data': x, 'labels_k': dict()}
        for i in range(nr_cluster_space.shape[0]):
            labels, _, err, _ = clustering(x, method=method, verbose=verbose, n_clusters=nr_cluster_space[i],
                                           categories=categories)

            # First entry gets the sum of the squared distances between each record and the assign cluster centroid
            scores[i, 0] = err
            if metrics is not None:
                scores[i, 1:], _ = score_clustering(x, labels, metrics=metrics)

            hyper_results['labels_k'][nr_cluster_space[i]] = labels

    elif method == 'DBSCAN':
        # Get the hyper-parameter space to run from the hyper-parameters introduced
        eps_space = np.linspace(params['min_eps'], params['max_eps'], params['nr_steps_eps'] + 1)
        min_samples_space = np.linspace(params['min_samples_min'], params['min_samples_max'],
                                        params['nr_steps_min_samples'] + 1)

        # Initialize the array for metrics and the key for their plot
        scores = np.zeros((eps_space.shape[0], min_samples_space.shape[0], 2 + sh))         # cubic shape
        key = (eps_space, min_samples_space)

        hyper_results = {'ohe_data': x, 'labels_k': dict()}
        for i in range(eps_space.shape[0]):
            for j in range(min_samples_space.shape[0]):
                labels, _, _, _ = clustering(x, method=method, verbose=verbose, eps=eps_space[i],
                                             min_samples=int(min_samples_space[j]))

                # First entry gets the number of clusters estimated.
                # Second entry gets the percentage of records not labeled by DBSCAN (label -1)
                scores[i, j, 0] = len(set(labels)) - (1 if -1 in labels else 0)
                scores[i, j, 1] = sum(labels == -1)*100/len(labels)
                if metrics is not None:
                    scores[i, j, 2:], _ = score_clustering(x[labels != -1, :], labels[labels != -1], metrics=metrics)

                hyper_results['labels_k'][str(eps_space[i]) + ' | ' + min_samples_space[j]] = labels

    # If the method chosen is still not implemented
    else:
        raise KeyError('Model chosen is not supported. Choose model of: {}'.format(methods))

    return scores, key, hyper_results


# todo to delete once Explainability class is running without bugs
def explainability(data, params, labels, cluster_name='', save_path=''):
    """
    Function to decode the used data and plot the features to provide explainability to the clusters

    :param data: encoded data used in the model (scipy.sparse.csr_matrix)
    :param params: dictionary with each feature encoder and location in the total array
    :param labels: array with the assigned cluster label to each record
    :param cluster_name: name of the cluster to print on the plots
    :param save_path: path to save pictures to
    :return: Plots
    """

    print('Performing explainability plots...')

    # Style and colors to use in plots
    # plt.style.use('ggplot')
    # plt.rcParams['figure.facecolor'] = 'w'
    main_color_sns = 'darkslategrey'
    main_color_mpl = 'salmon'

    # Find which variables were encoded as continuous, binary or multilabel
    cont_params = {enc.name: [enc.encoder, enc.pos, enc.gamma] for enc in params if
                   isinstance(enc.encoder, MinMaxScaler)}
    multi_params = {enc.name: [enc.encoder, enc.pos, enc.gamma] for enc in params if
                    isinstance(enc.encoder, MultiLabelBinarizer)}
    cat_params = {enc.name: [enc.encoder, enc.pos, enc.gamma] for enc in params
                  if enc.name not in list(cont_params.keys()) + list(multi_params.keys())}

    # cont_params = {key: param for key, param in params.items() if isinstance(param[0], MinMaxScaler)}
    # multi_params = {key: param for key, param in params.items() if isinstance(param[0], MultiLabelBinarizer)}
    # cat_params = {key: param for key, param in params.items()
    #               if key not in list(cont_params.keys()) + list(multi_params.keys())}

    # Calculate the number of plots and how to place them in each figure
    nr_labels = len(np.unique(labels))
    if np.sqrt(nr_labels).is_integer():
        rows = cols = int(np.sqrt(nr_labels))
    else:
        cols = int(np.ceil(np.sqrt(nr_labels)))
        rows = int(nr_labels // cols + (1 if nr_labels % cols > 0 else 0))

    # Create one figure for each feature
    for key, param in {**cont_params, **multi_params, **cat_params}.items():  # params.items():

        # Initialize figure settings
        fig = plt.figure(figsize=(20, 10))
        plt.grid(True)
        if key[:4] == 'log_':
            key_title = key[4:]
        else:
            key_title = key
        plt.suptitle(cluster_name + ' | ' + 'Frequency of ' + key_title, size='xx-large', weight='bold')

        _xmax = 1
        _xmin = 0
        for i in range(nr_labels):
            # Get data for the current cluster
            data_lab = data.tocsr()[labels == np.unique(labels)[i], :]

            # Get # population for current cluster
            pop = data_lab.shape[0]
            ax = plt.subplot(rows, cols, i + 1)
            ax.text(0.7, 1.05, 'population='+str(pop), color='k', transform=ax.transAxes)

            # For continuous variables plot an histogram
            if key in cont_params.keys():
                values = data_lab[:, param[1][0]:param[1][1]].toarray() / param[2]
                values = param[0].inverse_transform(values).ravel()

                if key[:4] == 'log_':
                    values = np.expm1(values)

                _counts = pd.Series(values).value_counts(normalize=True).sort_index()*100
                if _counts.shape[0] < 30:
                    ax.scatter(_counts.index, _counts.values, color='mediumblue')
                    for k, v in _counts.iteritems():
                        ax.text(k, v + 10, str(round(v)), color='k', rotation=90, fontsize=8)

                    ax.set_ylim(0, 115)
                    ax.set_ylabel('%')
                    ax.yaxis.set_label_coords(-0.02, 1)
                    ax.xaxis.set_tick_params(labelsize=6)
                    _range_x = _counts.index
                else:
                    val = take_outliers_graph(values)
                    sns.distplot(val, bins=50, ax=ax, color=main_color_sns, kde_kws={'color': 'red'})
                    _range_x = val

                plt.xticks(rotation=45)
                _xmin = np.min([_xmin, _range_x.min()])
                _xmax = np.max([_xmax, _range_x.max()])

            # For categorical variables plot bar plots with the count of the most frequent categories
            elif key in cat_params.keys():
                values = (data_lab[:, param[1][0]:param[1][1]].toarray()/param[2]).astype(int)
                values = param[0].inverse_transform(values).ravel()
                values = ['\n'.join(wrap(str(l), 20)) for l in values]
                val = pd.value_counts(pd.Series(values, name=key), sort=False, ascending=False, normalize=True) * 100
                index = val.sort_values(ascending=False)[:10].index.tolist()
                val[index].sort_index().plot(kind='bar', ax=ax, rot=45, color=main_color_mpl, alpha=0.5)

                for k, v in enumerate(val[index].sort_index()):
                    ax.text(k, v + 10, str(round(v)), color='k', rotation=90, fontsize=8)
                ax.set_ylim(0, 115)
                ax.set_ylabel('%')
                ax.yaxis.set_label_coords(-0.02, 1)
                ax.xaxis.set_tick_params(labelsize=6)

            # For Multi categorical variables plot most frequent labels according to their frequency
            elif key in multi_params.keys():
                values = (data_lab[:, param[1][0]:param[1][1]].toarray()/param[2]).astype(int)
                lbs = param[0].classes_

                # Get percentages of existence of each extra for the cluster
                per = values.sum(axis=0) * 100 / values.shape[0]
                val = pd.Series(per, name=key, index=lbs).sort_values(ascending=False)
                val[:30].plot(kind='bar', ax=ax, color=main_color_mpl, alpha=0.5)
                for k, v in enumerate(val[:30]):
                    ax.text(k - 0.1, v + 10, str(round(v)), color='k', rotation=90, fontsize=6)
                ax.set_ylim(0, 115)
                ax.set_ylabel('%')
                ax.yaxis.set_label_coords(-0.02, 1)

            ax.set_title('Cluster ' + str(np.unique(labels)[i]), pad=15, weight='semibold')

        # Properties to rearrange the plots within each picture
        plt.subplots_adjust(top=0.9, bottom=0.106, left=0.036, right=0.966, hspace=0.545, wspace=0.198)
        if key in cont_params.keys():
            for i in range(nr_labels):
                ax = plt.subplot(rows, cols, i + 1)
                ax.set_xlim(_xmin - 0.05*(_xmax-_xmin)/_xmax, _xmax*1.05)
        #
        #     plt.subplots_adjust(top=0.9, bottom=0.106, left=0.036, right=0.966, hspace=0.545, wspace=0.198)
        #
        # elif key in cat_params.keys():
        #     plt.subplots_adjust(top=0.9, bottom=0.106, left=0.036, right=0.966, hspace=0.545, wspace=0.198)
        #
        # elif key in multi_params.keys():
        #     plt.subplots_adjust(top=0.9, bottom=0.106, left=0.036, right=0.966, hspace=0.545, wspace=0.198)

        # Save the plots to the correct folder
        if save_path != '':
            fig.savefig(save_path + '/' + cluster_name + '_' + 'frequency_of_' +
                        key_title.replace('/', '_per_').replace(' |', '').replace(' ', '_') + '.png')
            plt.close(fig)
        else:
            print('Path to save pictures was not given. Will not save.')

    return


def eval_cluster_fitness(err, dim, silhouette=None, nr_votes=3):
    """
    Function to find the optimal number of clusters by analysing the sum of the squared distances values

    :param numpy.ndarray err: sum of squared distances array
    :param tuple dim: shape of the encoded data passed to the clustering model
    :param numpy.ndarray silhouette: default: None. Vector containing the mean silhouette values for each clustering
    iteration

    :return int: Best number of clusters found
    """
    # todo include metrics evaluation

    print('Printing estimation for best number of clusters...')

    est = WeightedEstimator(estimators=('AsankaPerera', 'Riddle', 'PhamDimovNguyen', 'GapStatistic'))
    est.fit_s_k(err, dim)
    best_ks = est.get_nr_cluster(nr_votes=nr_votes)
    k = int(best_ks[0])

    print('Number of clusters estimated for sub_cluster is {}'.format(k))

    return k


def check_params(params, alg):
    """Function to check if the hyper-parameters passed are well defined according to the algorithm chosen.
    If something is wrong an exception will be raised.

    :param dict params: algorithm hyper-parameters to explore
    :param string alg: algorithm to cluster with
    :return: None
    """

    alg_params = {'kmeans':             {'min_n_clusters', 'max_n_clusters'},
                  'minibatchkmeans':    {'min_n_clusters', 'max_n_clusters'},
                  'kmodes':             {'min_n_clusters', 'max_n_clusters'},
                  'kprototypes':        {'min_n_clusters', 'max_n_clusters'},
                  'DBSCAN':             {'min_eps', 'max_eps', 'nr_steps_eps', 'min_samples_min', 'min_samples_max',
                                         'nr_steps_min_samples'}}
    alg_params_type = {'kmeans':            [int],
                       'minibatchkmeans':   [int],
                       'kmodes':            [int],
                       'kprototypes':       [int],
                       'DBSCAN':            [int, float]}

    if params is not None:
        if type(params) == dict:
            if not alg_params[alg].issubset(set(params.keys())):
                raise KeyError('Parameters keys passed are invalid for method chosen.')
            if not all(type(value) in alg_params_type[alg] for key, value in params.items()
                       if key in alg_params[alg]):
                raise TypeError('Parameters values types passed are invalid for method chosen.')
        else:
            raise TypeError('Parameters variable passed is not in dict format.')
    else:
        raise ValueError('Parameters variable was not passed.')

    return


def check_metrics(metrics):
    """Function to check if the metrics passed are supported. If any of the passed metrics is not implemented,
    an error will be raised. todo instead of raising an exception, pass a warning and disregard not implemented metrics

    :param list|string metrics: List with metrics, 'all' or None
    :return list: metrics to be evaluated
    """

    metrics_supported = ['Silhouette Coefficient', 'Calinski-Harabasz', 'Davies-Bouldin'] #, 'Scatter Separability'}

    if type(metrics) != list:
        metrics = [metrics]

    # If 'all' or None, go through
    if not (((metrics[0] == 'all') or (metrics[0] is None)) and (len(metrics) == 1)):
        # If input is not a subset of the supported metrics, raise exception
        if not set(metrics).issubset(metrics_supported):
            raise KeyError('One or some metrics chosen is not supported.')

    if metrics == ['all']:
        return metrics_supported
    else:
        return metrics
